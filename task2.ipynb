{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ab9a56-7ef2-4a3a-8b7a-d5de41dc9165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/15 20:18:58 WARN Utils: Your hostname, Jordan, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "26/01/15 20:18:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/lior/.venv3.11/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/lior/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/lior/.ivy2.5.2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency\n",
      "org.apache.spark#spark-token-provider-kafka-0-10_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-834e36a8-77f8-41fe-971e-6ce164e30816;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.13;4.1.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.13;4.1.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.9.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.8 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.17 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.4.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.4.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.scala-lang.modules#scala-parallel-collections_2.13;1.2.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.12.1 in central\n",
      ":: resolution report :: resolve 793ms :: artifacts dl 34ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.12.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.4.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.4.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.9.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.13;4.1.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.13;4.1.1 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-parallel-collections_2.13;1.2.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.17 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-834e36a8-77f8-41fe-971e-6ce164e30816\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/14ms)\n",
      "26/01/15 20:19:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/15 20:19:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"EV-Stream\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ddce685-e135-4117-8877-529528edebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"ev_topic\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d90b7c-87f9-444f-bbee-ad77c472af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224682c4-87c5-480f-86ae-58676fe9f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = df.selectExpr(\"CAST(value AS STRING) as value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c8f91e-39b7-414d-b28a-87c9af847b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/15 20:21:00 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-16f7fe09-3119-4f82-9a5b-b0eb00ae7fab. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "26/01/15 20:21:00 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7d3bf7c91690>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"VIN (1-10)\": \"KM8K33AGXL\", \"County\": \"King\", \"City\": \"Seattle\", \"State\": \"WA\", \"Postal Code\": \"98103\", \"Model Year\": \"2020\", \"Make\": \"HYUNDAI\", \"Model\": \"KONA\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"258\", \"Base MSRP\": \"0\", \"Legislative District\": \"43\", \"DOL Vehicle ID\": \"249675142\", \"Vehicle Location\": \"POINT (-122.34301 47.659185)\", \"Electric Utility\": \"CITY OF SEATTLE - (WA)|CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033004800\"}                      |\n",
      "|{\"VIN (1-10)\": \"1C4RJYB61N\", \"County\": \"King\", \"City\": \"Bothell\", \"State\": \"WA\", \"Postal Code\": \"98011\", \"Model Year\": \"2022\", \"Make\": \"JEEP\", \"Model\": \"GRAND CHEROKEE\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Not eligible due to low battery range\", \"Electric Range\": \"25\", \"Base MSRP\": \"0\", \"Legislative District\": \"1\", \"DOL Vehicle ID\": \"233928502\", \"Vehicle Location\": \"POINT (-122.20578 47.762405)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033021804\"}          |\n",
      "|{\"VIN (1-10)\": \"1C4RJYD61P\", \"County\": \"Yakima\", \"City\": \"Yakima\", \"State\": \"WA\", \"Postal Code\": \"98908\", \"Model Year\": \"2023\", \"Make\": \"JEEP\", \"Model\": \"GRAND CHEROKEE\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Not eligible due to low battery range\", \"Electric Range\": \"25\", \"Base MSRP\": \"0\", \"Legislative District\": \"14\", \"DOL Vehicle ID\": \"229675939\", \"Vehicle Location\": \"POINT (-120.6027202 46.5965625)\", \"Electric Utility\": \"PACIFICORP\", \"2020 Census Tract\": \"53077002900\"}                                        |\n",
      "|{\"VIN (1-10)\": \"5YJ3E1EA7J\", \"County\": \"King\", \"City\": \"Kirkland\", \"State\": \"WA\", \"Postal Code\": \"98034\", \"Model Year\": \"2018\", \"Make\": \"TESLA\", \"Model\": \"MODEL 3\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"215\", \"Base MSRP\": \"0\", \"Legislative District\": \"45\", \"DOL Vehicle ID\": \"104714466\", \"Vehicle Location\": \"POINT (-122.209285 47.71124)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033021903\"}                   |\n",
      "|{\"VIN (1-10)\": \"WBY7Z8C5XJ\", \"County\": \"Thurston\", \"City\": \"Olympia\", \"State\": \"WA\", \"Postal Code\": \"98501\", \"Model Year\": \"2018\", \"Make\": \"BMW\", \"Model\": \"I3\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"97\", \"Base MSRP\": \"0\", \"Legislative District\": \"22\", \"DOL Vehicle ID\": \"185498386\", \"Vehicle Location\": \"POINT (-122.89692 47.043535)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53067010700\"}                                       |\n",
      "|{\"VIN (1-10)\": \"5YJ3E1EAXL\", \"County\": \"Snohomish\", \"City\": \"Marysville\", \"State\": \"WA\", \"Postal Code\": \"98271\", \"Model Year\": \"2020\", \"Make\": \"TESLA\", \"Model\": \"MODEL 3\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"266\", \"Base MSRP\": \"0\", \"Legislative District\": \"38\", \"DOL Vehicle ID\": \"124595523\", \"Vehicle Location\": \"POINT (-122.1713847 48.10433)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53061940001\"}                                  |\n",
      "|{\"VIN (1-10)\": \"2C4RC1N77H\", \"County\": \"King\", \"City\": \"Kent\", \"State\": \"WA\", \"Postal Code\": \"98042\", \"Model Year\": \"2017\", \"Make\": \"CHRYSLER\", \"Model\": \"PACIFICA\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"33\", \"Base MSRP\": \"0\", \"Legislative District\": \"47\", \"DOL Vehicle ID\": \"1815593\", \"Vehicle Location\": \"POINT (-122.111625 47.36078)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033031707\"}              |\n",
      "|{\"VIN (1-10)\": \"5YJYGDEE3L\", \"County\": \"King\", \"City\": \"Woodinville\", \"State\": \"WA\", \"Postal Code\": \"98072\", \"Model Year\": \"2020\", \"Make\": \"TESLA\", \"Model\": \"MODEL Y\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"291\", \"Base MSRP\": \"0\", \"Legislative District\": \"45\", \"DOL Vehicle ID\": \"124760555\", \"Vehicle Location\": \"POINT (-122.151665 47.75855)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033021906\"}                |\n",
      "|{\"VIN (1-10)\": \"5YJ3E1EA1J\", \"County\": \"Island\", \"City\": \"Coupeville\", \"State\": \"WA\", \"Postal Code\": \"98239\", \"Model Year\": \"2018\", \"Make\": \"TESLA\", \"Model\": \"MODEL 3\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"215\", \"Base MSRP\": \"0\", \"Legislative District\": \"10\", \"DOL Vehicle ID\": \"125048003\", \"Vehicle Location\": \"POINT (-122.6880708 48.2179983)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53029971000\"}                                   |\n",
      "|{\"VIN (1-10)\": \"7SAYGDEF0P\", \"County\": \"King\", \"City\": \"Bellevue\", \"State\": \"WA\", \"Postal Code\": \"98004\", \"Model Year\": \"2023\", \"Make\": \"TESLA\", \"Model\": \"MODEL Y\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Eligibility unknown as battery range has not been researched\", \"Electric Range\": \"0\", \"Base MSRP\": \"0\", \"Legislative District\": \"48\", \"DOL Vehicle ID\": \"240416207\", \"Vehicle Location\": \"POINT (-122.201905 47.61385)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033023806\"}|\n",
      "|{\"VIN (1-10)\": \"5YJ3E1EA7J\", \"County\": \"King\", \"City\": \"Kirkland\", \"State\": \"WA\", \"Postal Code\": \"98033\", \"Model Year\": \"2018\", \"Make\": \"TESLA\", \"Model\": \"MODEL 3\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"215\", \"Base MSRP\": \"0\", \"Legislative District\": \"48\", \"DOL Vehicle ID\": \"231013436\", \"Vehicle Location\": \"POINT (-122.20264 47.6785)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033022603\"}                     |\n",
      "|{\"VIN (1-10)\": \"3FA6P0SU9G\", \"County\": \"Kitsap\", \"City\": \"Port Orchard\", \"State\": \"WA\", \"Postal Code\": \"98367\", \"Model Year\": \"2016\", \"Make\": \"FORD\", \"Model\": \"FUSION\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Not eligible due to low battery range\", \"Electric Range\": \"19\", \"Base MSRP\": \"0\", \"Legislative District\": \"26\", \"DOL Vehicle ID\": \"212561716\", \"Vehicle Location\": \"POINT (-122.6851642 47.506453)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53035092902\"}                               |\n",
      "|{\"VIN (1-10)\": \"JTDKARFP9H\", \"County\": \"Kitsap\", \"City\": \"Port Orchard\", \"State\": \"WA\", \"Postal Code\": \"98366\", \"Model Year\": \"2017\", \"Make\": \"TOYOTA\", \"Model\": \"PRIUS PRIME\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Not eligible due to low battery range\", \"Electric Range\": \"25\", \"Base MSRP\": \"0\", \"Legislative District\": \"26\", \"DOL Vehicle ID\": \"229764972\", \"Vehicle Location\": \"POINT (-122.639265 47.5373)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53035092600\"}                           |\n",
      "|{\"VIN (1-10)\": \"5YJ3E1EB8K\", \"County\": \"Snohomish\", \"City\": \"Mukilteo\", \"State\": \"WA\", \"Postal Code\": \"98275\", \"Model Year\": \"2019\", \"Make\": \"TESLA\", \"Model\": \"MODEL 3\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"220\", \"Base MSRP\": \"0\", \"Legislative District\": \"21\", \"DOL Vehicle ID\": \"179728755\", \"Vehicle Location\": \"POINT (-122.299965 47.94171)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53061041301\"}                                     |\n",
      "|{\"VIN (1-10)\": \"5YJ3E1EA5K\", \"County\": \"King\", \"City\": \"Redmond\", \"State\": \"WA\", \"Postal Code\": \"98052\", \"Model Year\": \"2019\", \"Make\": \"TESLA\", \"Model\": \"MODEL 3\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"220\", \"Base MSRP\": \"0\", \"Legislative District\": \"45\", \"DOL Vehicle ID\": \"120633516\", \"Vehicle Location\": \"POINT (-122.12302 47.67668)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC||CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033032323\"}                     |\n",
      "|{\"VIN (1-10)\": \"3FA6P0SU0D\", \"County\": \"Thurston\", \"City\": \"Rochester\", \"State\": \"WA\", \"Postal Code\": \"98579\", \"Model Year\": \"2013\", \"Make\": \"FORD\", \"Model\": \"FUSION\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Not eligible due to low battery range\", \"Electric Range\": \"19\", \"Base MSRP\": \"0\", \"Legislative District\": \"20\", \"DOL Vehicle ID\": \"138697212\", \"Vehicle Location\": \"POINT (-123.09573 46.82158)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53067012730\"}                                   |\n",
      "|{\"VIN (1-10)\": \"WA1VABGE4K\", \"County\": \"King\", \"City\": \"Seattle\", \"State\": \"WA\", \"Postal Code\": \"98112\", \"Model Year\": \"2019\", \"Make\": \"AUDI\", \"Model\": \"E-TRON\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"204\", \"Base MSRP\": \"0\", \"Legislative District\": \"43\", \"DOL Vehicle ID\": \"475364046\", \"Vehicle Location\": \"POINT (-122.306935 47.62441)\", \"Electric Utility\": \"CITY OF SEATTLE - (WA)|CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033006400\"}                       |\n",
      "|{\"VIN (1-10)\": \"1N4AZ0CP6F\", \"County\": \"King\", \"City\": \"Seattle\", \"State\": \"WA\", \"Postal Code\": \"98125\", \"Model Year\": \"2015\", \"Make\": \"NISSAN\", \"Model\": \"LEAF\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"84\", \"Base MSRP\": \"0\", \"Legislative District\": \"46\", \"DOL Vehicle ID\": \"252522896\", \"Vehicle Location\": \"POINT (-122.296385 47.71558)\", \"Electric Utility\": \"CITY OF SEATTLE - (WA)|CITY OF TACOMA - (WA)\", \"2020 Census Tract\": \"53033000201\"}                        |\n",
      "|{\"VIN (1-10)\": \"KNDCC3LD7K\", \"County\": \"Kitsap\", \"City\": \"Bremerton\", \"State\": \"WA\", \"Postal Code\": \"98311\", \"Model Year\": \"2019\", \"Make\": \"KIA\", \"Model\": \"NIRO\", \"Electric Vehicle Type\": \"Plug-in Hybrid Electric Vehicle (PHEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Not eligible due to low battery range\", \"Electric Range\": \"26\", \"Base MSRP\": \"0\", \"Legislative District\": \"23\", \"DOL Vehicle ID\": \"2148170\", \"Vehicle Location\": \"POINT (-122.6468815 47.6344364)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53035091204\"}                                      |\n",
      "|{\"VIN (1-10)\": \"1N4AZ0CP1E\", \"County\": \"Kitsap\", \"City\": \"Poulsbo\", \"State\": \"WA\", \"Postal Code\": \"98370\", \"Model Year\": \"2014\", \"Make\": \"NISSAN\", \"Model\": \"LEAF\", \"Electric Vehicle Type\": \"Battery Electric Vehicle (BEV)\", \"Clean Alternative Fuel Vehicle (CAFV) Eligibility\": \"Clean Alternative Fuel Vehicle Eligible\", \"Electric Range\": \"84\", \"Base MSRP\": \"0\", \"Legislative District\": \"23\", \"DOL Vehicle ID\": \"258176922\", \"Vehicle Location\": \"POINT (-122.64177 47.737525)\", \"Electric Utility\": \"PUGET SOUND ENERGY INC\", \"2020 Census Tract\": \"53035091100\"}                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/15 20:23:20 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Call(callName=describeTopicPartitions, deadlineMs=1768501349000, tries=1, nextAllowedTryMs=1768501400906) timed out at 1768501400788 after 1 attempt(s)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:65)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:64)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:447)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:466)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:446)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:302)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:149)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:773)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:772)\n",
      "\tat scala.collection.immutable.List.map(List.scala:236)\n",
      "\tat scala.collection.immutable.List.map(List.scala:79)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:761)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:1335)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:757)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:492)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:481)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:71)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.execute(TriggerExecutor.scala:83)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Call(callName=describeTopicPartitions, deadlineMs=1768501349000, tries=1, nextAllowedTryMs=1768501400906) timed out at 1768501400788 after 1 attempt(s)\n",
      "Caused by: org.apache.kafka.common.errors.DisconnectException: Cancelled describeTopicPartitions request with correlation id 3164 due to node 1 being disconnected\n",
      "26/01/15 20:24:05 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listOffsets(api=LIST_OFFSETS)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.listOffsets(KafkaOffsetReaderAdmin.scala:87)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$fetchLatestOffsets$1(KafkaOffsetReaderAdmin.scala:337)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:449)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:466)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:446)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:302)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:149)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:773)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:772)\n",
      "\tat scala.collection.immutable.List.map(List.scala:236)\n",
      "\tat scala.collection.immutable.List.map(List.scala:79)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:761)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:1335)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:757)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:492)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:481)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:71)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.execute(TriggerExecutor.scala:83)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listOffsets(api=LIST_OFFSETS)\n",
      "26/01/15 20:24:50 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Call(callName=describeTopicPartitions, deadlineMs=1768501439206, tries=1, nextAllowedTryMs=1768501491093) timed out at 1768501490988 after 1 attempt(s)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:65)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:64)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:447)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:466)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:446)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:302)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:149)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:773)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:772)\n",
      "\tat scala.collection.immutable.List.map(List.scala:236)\n",
      "\tat scala.collection.immutable.List.map(List.scala:79)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:761)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:1335)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:757)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:492)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:481)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:71)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.execute(TriggerExecutor.scala:83)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Call(callName=describeTopicPartitions, deadlineMs=1768501439206, tries=1, nextAllowedTryMs=1768501491093) timed out at 1768501490988 after 1 attempt(s)\n",
      "Caused by: org.apache.kafka.common.errors.DisconnectException: Cancelled describeTopicPartitions request with correlation id 9240 due to node 1 being disconnected\n",
      "26/01/15 20:24:56 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: \n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:65)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:64)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:447)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:466)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:446)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:302)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:149)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:773)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:772)\n",
      "\tat scala.collection.immutable.List.map(List.scala:236)\n",
      "\tat scala.collection.immutable.List.map(List.scala:79)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:761)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:1335)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:757)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:492)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:481)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:71)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.execute(TriggerExecutor.scala:83)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "26/01/15 20:25:01 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: \n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:65)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:64)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:447)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:466)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:446)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:302)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:149)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:773)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:772)\n",
      "\tat scala.collection.immutable.List.map(List.scala:236)\n",
      "\tat scala.collection.immutable.List.map(List.scala:79)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:761)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:1335)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:757)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:492)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:481)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:71)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.execute(TriggerExecutor.scala:83)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "26/01/15 20:23:10 ERROR MicroBatchExecution: Query [id = e1680a31-accc-469c-9e35-5ee94f6494a0, runId = e60a8639-7b17-4b18-a5eb-67be70b3c255] terminated with error\n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:65)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:64)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:447)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:466)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:446)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:302)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:149)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:773)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:772)\n",
      "\tat scala.collection.immutable.List.map(List.scala:236)\n",
      "\tat scala.collection.immutable.List.map(List.scala:79)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:761)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:1335)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:757)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:492)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:481)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.runOneBatch(TriggerExecutor.scala:71)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.ProcessingTimeExecutor.execute(TriggerExecutor.scala:83)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:461)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\n",
      "\tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n"
     ]
    }
   ],
   "source": [
    "q1 = (\n",
    "    text_df.writeStream\n",
    "    .format(\"console\")\n",
    "    .option(\"truncate\", \"false\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a3139e-41de-408c-a227-76742a75d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b197c6a-cade-4074-a3eb-8c7ea51cba64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
